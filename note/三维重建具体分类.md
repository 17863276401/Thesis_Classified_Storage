# 三维重建具体分类

三维重建（3D Reconstruction）是将真实世界的物体或场景转化为计算机中的三维数字模型的过程。这是一个跨越计算机视觉（CV）、计算机图形学（CG）和传感器技术的综合领域。

根据数据获取方式、算法原理及最终的表达形式，三维重建可以从以下几个主要维度进行分类：

### 1. 按数据获取方式分类 (Data Acquisition)

这是最基础的分类方式，取决于是否人为地向场景投射信号。

#### **A. 被动式重建 (Passive Methods)**

不主动发射信号，仅依靠相机接收环境光（类似于人眼）。

- **多视图立体视觉 (Multi-View Stereo, MVS):** 利用从不同角度拍摄的多张图像，通过特征匹配和三角测量恢复三维结构。这是目前最主流的视觉重建方法（如 Colmap）。
- **运动恢复结构 (Structure from Motion, SfM):** 从视频或无序图像集合中同时估计相机位姿和稀疏点云。通常作为MVS的前置步骤。
- **单目重建 (Monocular Reconstruction):** 仅用一张RGB图像推断三维结构。主要依赖深度学习学习先验知识（如单目深度估计）。
- **SLAM (Simultaneous Localization and Mapping):** 侧重于实时的相机定位和稀疏/半稠密地图构建，常用于机器人导航。

#### **B. 主动式重建 (Active Methods)**

主动向物体发射信号（光、激光、声波），通过接收反射信号来计算深度。

- **激光雷达 (LiDAR):** 发射激光束测量飞行时间（ToF）。精度极高，抗干扰强，常用于自动驾驶和测绘。
  - *机械式 vs 固态 LiDAR*
- **结构光 (Structured Light):** 投射特定的光栅图案（如条纹、散斑）到物体表面，根据图案的畸变计算深度（如 iPhone FaceID, Kinect V1）。
- **飞行时间法 (Time of Flight, ToF):** 向目标连续发送光脉冲，计算光往返时间（如 Kinect V2）。

------

### 2. 按场景表达形式分类 (Scene Representation)

这是近年来随着神经渲染技术兴起后变化最大的分类维度。

#### **A. 显式表达 (Explicit Representation)**

直接定义物体的几何形状。

- **点云 (Point Cloud):** 离散的3D点集合 $(x, y, z, r, g, b)$。这是LiDAR和SfM的直接输出，数据量大但不具备拓扑信息。
- **网格 (Mesh):** 由顶点、边和面（通常是三角面片）组成。是传统图形学渲染的标准格式。
- **体素 (Voxel):** 类似于3D像素（立方体网格）。常用于早期的深度学习方法，但内存占用高。
- **3D Gaussian Splatting (3DGS):** **[前沿]** 使用成千上万个带有各向异性协方差的3D高斯球来表示场景。它既是显式的（有明确的中心和形状），又通过可微光栅化实现了极高的渲染速度和质量。

#### **B. 隐式表达 (Implicit Representation)**

不直接存储几何数据，而是通过函数 $f(x, y, z)$ 来定义形状。

- **神经辐射场 (NeRF):** 使用多层感知机（MLP）将空间坐标和视角映射为体密度和颜色。优点是照片级真实感，缺点是训练和推理慢（虽然已有Instant-NGP等加速方案）。
- **符号距离场 (Signed Distance Function, SDF):** 学习空间中任意一点到最近物体表面的距离。$f(x)>0$ 在外，$f(x)<0$ 在内，$f(x)=0$ 即为表面。非常适合重建高质量的平滑表面（如 NeuS, VolSDF）。

------

### 3. 按算法原理分类 (Algorithm Paradigm)

| **分类**                        | **特点**                                                     | **代表技术**                                       |
| ------------------------------- | ------------------------------------------------------------ | -------------------------------------------------- |
| **传统几何方法**                | 基于多视图几何原理，鲁棒性好，精度高，但对弱纹理、反光区域处理差。 | SfM (Colmap), MVS (MVSNet), Delaunay Triangulation |
| **基于深度学习的方法**          | 利用神经网络学习深度先验，能处理单目或病态场景。             | DeepMVS, Pix2Vox                                   |
| **神经渲染 (Neural Rendering)** | **[当前主流]** 结合了深度学习和物理渲染方程，直接优化3D表达以拟合2D图像。 | NeRF, 3DGS, NeuS                                   |

### 4. 按场景动态性分类 (Scene Dynamics)

- **静态重建 (Static Reconstruction):** 假设场景中的物体是静止的（如建筑物、文物）。
- **动态重建 (Dynamic/4D Reconstruction):** 重建随时间变化的场景（如人物表演、流体）。通常需要引入时间维度 $t$，称为 4D Reconstruction (Space + Time)。

### 总结与趋势

目前的学术和工业界趋势正从传统的 **"SfM -> MVS -> Mesh"** 流程，向 **"SfM -> 3DGS/NeRF"** 转变。

- 如果追求**工业测绘和几何精度**，**LiDAR** 和 **传统MVS** 仍是首选。
- 如果追求**照片级视觉效果和实时渲染**，**3D Gaussian Splatting (3DGS)** 是目前的SOTA（State-of-the-Art）。
- 如果追求**表面重建的完整性**（水密模型），基于 **SDF** 的神经隐式方法（如 Neuralangelo）表现最好。